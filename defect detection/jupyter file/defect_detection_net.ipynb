{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os \n",
    "import torch\n",
    "import json\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset, ConcatDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "torch.manual_seed(7)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_defectDetection(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        super(dataset_defectDetection, self).__init__()\n",
    "        self.path = path\n",
    "        self.component = [\"data\", \"label\"]\n",
    "        self.transform = transform\n",
    "        self.path_data = os.path.join(self.path, self.component[0])\n",
    "        self.path_label = os.path.join(self.path, self.component[1])\n",
    "        dataList, _, _ = os.walk(self.path_data)\n",
    "        self.data = [os.path.join(self.path_data, data_name) for data_name in dataList[-1]]\n",
    "        self.label = [os.path.join(self.path_label, label_name) for label_name in os.listdir(self.path_label)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        # 根据索引生成标签\n",
    "        path_label = self.label[item]\n",
    "        with open(path_label, \"r\", encoding=\"utf8\") as fp:\n",
    "            label = json.load(fp)\n",
    "            label_mask = np.zeros((label[\"imageHeight\"], label[\"imageWidth\"]), np.uint8)\n",
    "            for i in range(len(label[\"shapes\"])):\n",
    "                label_points = np.array(label[\"shapes\"][i][\"points\"], np.int32)\n",
    "                label_mask = cv2.drawContours(label_mask, [label_points], -1, 255, -1)\n",
    "        \n",
    "        # 根据标签查找图片(该数据集图片总共1104，带有标签的图片只有394)\n",
    "        path_image = os.path.join(self.path_data, os.path.splitext(os.path.split(path_label)[-1])[0] + \".jpg\")\n",
    "        image = Image.open(path_image)\n",
    "        \n",
    "        # 数据处理\n",
    "        if self.transform is not None:\n",
    "            random.seed(7)\n",
    "            image = self.transform(image) \n",
    "            random.seed(7)\n",
    "            label = self.transform(Image.fromarray(np.uint8(label_mask)))\n",
    "            label[label >= 0.5] = 1.\n",
    "            label[label < 0.5] = 0.\n",
    "        label = torch.cat([label, (1-label)], dim=0)\n",
    "        \n",
    "        # 返回图像和标签\n",
    "        return image, label\n",
    "    \n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    path = r\"C:\\Users\\风\\Desktop\\表面缺陷检测\\BSData-main\\BSData-main\"\n",
    "    input_size = (256, 512)\n",
    "    batch_size = 2\n",
    "    shuffle = True\n",
    "    num_workers = 0\n",
    "    pin_memory = True\n",
    "    drop_last = True\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    image_datasets = dataset_defectDetection(path, transform=transform)\n",
    "    torch.manual_seed(7) # 设置随机种子以便dataset分割的结果可重复\n",
    "    image_datasets_split = random_split(image_datasets, [len(image_datasets)//5, len(image_datasets)-len(image_datasets)//5])\n",
    "\n",
    "    loader = {\n",
    "        \"train\": DataLoader(image_datasets_split[1], batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=pin_memory, drop_last=drop_last),\n",
    "        \"eval\": DataLoader(image_datasets_split[0], batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=pin_memory, drop_last=drop_last), \n",
    "    }\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBG_layer(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature):\n",
    "        super(LBG_layer, self).__init__()\n",
    "        \n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        \n",
    "        self.lbg_conv = nn.Sequential(\n",
    "            nn.Linear(self.in_feature, self.out_feature),\n",
    "            nn.BatchNorm1d(self.out_feature),\n",
    "            nn.ReLU()\n",
    "#             nn.GELU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lbg_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBS_layer(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature):\n",
    "        super(LBS_layer, self).__init__()\n",
    "        \n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        \n",
    "        self.lbs_conv = nn.Sequential(\n",
    "            nn.Linear(self.in_feature, self.out_feature),\n",
    "            nn.BatchNorm1d(self.out_feature),\n",
    "            nn.Sigmoid()\n",
    "#             nn.GELU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lbs_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBG_layer(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature, kernel_size, stride, padding=0):\n",
    "        super(CBG_layer, self).__init__()\n",
    "        \n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.kernel_size  = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "        self.cbg_conv = nn.Sequential(\n",
    "            nn.Conv2d(self.in_feature, self.out_feature, self.kernel_size, self.stride, self.padding),\n",
    "            nn.BatchNorm2d(self.out_feature),\n",
    "            nn.ReLU()\n",
    "#             nn.GELU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cbg_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBS_layer(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature, kernel_size, stride, padding=0):\n",
    "        super(CBS_layer, self).__init__()\n",
    "        \n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.kernel_size  = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "        self.cbs_conv = nn.Sequential(\n",
    "            nn.Conv2d(self.in_feature, self.out_feature, self.kernel_size, self.stride, self.padding),\n",
    "            nn.BatchNorm2d(self.out_feature),\n",
    "            nn.Sigmoid()\n",
    "#             nn.GELU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.cbs_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBG_layer(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature, kernel_size, stride, padding=0, output_padding=0):\n",
    "        super(DBG_layer, self).__init__()\n",
    "        \n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.kernel_size = kernel_size \n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.output_padding = output_padding\n",
    "        \n",
    "        self.dbg_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(self.in_feature, self.out_feature, self.kernel_size, self.stride, self.padding, self.output_padding),\n",
    "            nn.BatchNorm2d(self.out_feature), \n",
    "            nn.ReLU()\n",
    "#             nn.GELU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.dbg_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scope_layer(nn.Module):\n",
    "    def __init__(self, n, in_feature, out_feature, kernel_size, stride, padding):\n",
    "        super(Scope_layer, self).__init__()\n",
    "        \n",
    "        self.n = n\n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.cbg_conv = CBG_layer(self.in_feature, self.out_feature, self.kernel_size, self.stride, self.padding)\n",
    "        \n",
    "        self.scope_conv = nn.Sequential(*[self.cbg_conv for i in range(self.n)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.scope_conv):\n",
    "            if i == 0:\n",
    "                x = layer(x)\n",
    "                x1 = x\n",
    "            else:\n",
    "                x1 = layer(x1)\n",
    "                x = torch.cat([x, x1], dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res_layer(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature, kernel_size, stride, padding):\n",
    "        super(Res_layer, self).__init__()\n",
    "        \n",
    "        self.in_feature = in_feature\n",
    "        self.out_feature = out_feature\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        \n",
    "        self.cbg_conv1 = CBG_layer(self.in_feature, int(self.in_feature/2), 1, 1)\n",
    "        self.cbg_conv2 = CBG_layer(int(self.in_feature/2), int(self.in_feature/2), self.kernel_size,  1, self.padding)\n",
    "        self.cbg_conv3 = CBG_layer(int(self.in_feature/2), self.out_feature-self.in_feature, 1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.cbg_conv1(x)\n",
    "        x1 = self.cbg_conv2(x1)\n",
    "        x1 = self.cbg_conv3(x1)\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegNet(nn.Module):\n",
    "    def __init__(self, input_size, device):\n",
    "        super(SegNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.device = device\n",
    "        \n",
    "        self.cbg_conv1 = CBG_layer(3, 6, 3, 1, 1)\n",
    "        self.scope_conv1 = Scope_layer(4, 6, 6, 3, 1, 1)\n",
    "        \n",
    "        self.cbg_conv2 = CBG_layer(3, 30, 1, 1)\n",
    "        self.pool1 = nn.AvgPool2d((input_size[0], input_size[1]), (1, 1), count_include_pad=False)\n",
    "        self.lbg_conv1 = LBG_layer(30, 5)\n",
    "        self.lbg_conv2 = LBG_layer(5, 30)\n",
    "        \n",
    "        self.cbg_conv3 = CBG_layer(30, 32, 5, 1, 2)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.res_conv1 = Res_layer(32, 64, 3, 1, 1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.res_conv2 = Res_layer(64, 128, 3, 1, 1)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.res_conv3 = Res_layer(128, 256, 3, 1, 1)\n",
    "        self.pool5 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.cbg_conv4 = CBG_layer(256, 256, 5, 1, 2)\n",
    "        \n",
    "        self.d_conv1 = DBG_layer(256, 128, 3, 2, 1, 1)\n",
    "        self.cbg_conv5 = CBG_layer(256, 256, 5, 1, 2)\n",
    "        self.d_conv2 = DBG_layer(256, 64, 3, 2, 1, 1)\n",
    "        self.cbg_conv6 = CBG_layer(128, 128, 5, 1, 2)\n",
    "        self.d_conv3 = DBG_layer(128, 32, 3, 2, 1, 1)\n",
    "        self.cbg_conv7 = CBG_layer(64, 64, 5, 1, 2)\n",
    "        self.d_conv4 = DBG_layer(64, 16, 3, 2, 1, 1)\n",
    "        \n",
    "        self.cbg_conv8 = CBG_layer(46, 32, 3, 1, 1)\n",
    "        self.cbg_conv9 = CBG_layer(32, 8, 3, 1, 1)\n",
    "\n",
    "        \n",
    "        self.pool6 = nn.AvgPool2d((int(input_size[0]/16), int(input_size[1]/16)), (1, 1), count_include_pad=False)\n",
    "        self.lbg_conv3 = LBG_layer(256, 8)\n",
    "\n",
    "        \n",
    "        self.cbg_conv10 = CBG_layer(8, 8, 3, 1, 1)\n",
    "        self.cbg_conv11 = CBG_layer(8, 2, 3, 1, 1)\n",
    " \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.cbg_conv1(x)\n",
    "        x2 = self.scope_conv1(x1)\n",
    "        x1 = torch.cat([x1, x2], dim=1)\n",
    "        \n",
    "        x = self.cbg_conv2(x)\n",
    "        x = self.pool1(x).view(x.shape[0], x.shape[1])\n",
    "        x = self.lbg_conv1(x)\n",
    "        x = self.lbg_conv2(x)\n",
    "        x = x1 * x.view(x.shape[0], x.shape[1], 1, 1)\n",
    "    \n",
    "        # encode part\n",
    "        x0 = x\n",
    "        x1 = self.cbg_conv3(x0)\n",
    "        x1 = self.pool2(x1)\n",
    "        x2 = self.res_conv1(x1)\n",
    "        x2 = self.pool3(x2)\n",
    "        x3 = self.res_conv2(x2)\n",
    "        x3 = self.pool4(x3)\n",
    "        x4 = self.res_conv3(x3)\n",
    "        x4 = self.pool5(x4)\n",
    "        x4 = self.cbg_conv4(x4)\n",
    "\n",
    "        \n",
    "        # decode part\n",
    "        x = self.d_conv1(x4)\n",
    "        x = torch.cat([x, x3], dim=1)\n",
    "        x = self.cbg_conv5(x)\n",
    "        x = self.d_conv2(x)\n",
    "        x = torch.cat([x, x2], dim=1)\n",
    "        x = self.cbg_conv6(x)\n",
    "        x = self.d_conv3(x)\n",
    "        x = torch.cat([x, x1], dim=1)\n",
    "        x = self.cbg_conv7(x)\n",
    "        x = self.d_conv4(x)\n",
    "        x = torch.cat([x, x0], dim=1)\n",
    "        x = self.cbg_conv8(x)\n",
    "        x = self.cbg_conv9(x)\n",
    "        \n",
    "        \n",
    "        x4 = self.pool6(x4).view(x4.shape[0], x4.shape[1])\n",
    "        x4 = self.lbg_conv3(x4)\n",
    "        x = x * x4.view(x4.shape[0], x4.shape[1], 1, 1)\n",
    "        x = self.cbg_conv10(x)\n",
    "        x = self.cbg_conv11(x)\n",
    "        x = nn.Softmax(dim=1)(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class evaluator():\n",
    "    def __init__(self, outputs, labels):\n",
    "        self.outputs = outputs\n",
    "        self.labels = labels\n",
    "        self.shape = self.outputs.shape\n",
    "    \n",
    "    def loss_fn(self):\n",
    "        loss_value = nn.BCELoss()(self.outputs, self.labels)\n",
    "        return loss_value\n",
    "    \n",
    "    def acc_fn(self):\n",
    "        self.outputs = self.outputs.cpu()\n",
    "        self.labels = self.labels.cpu()\n",
    "        self.outputs[self.outputs >= 0.5] = 1.\n",
    "        self.outputs[self.outputs < 0.5] = 0. \n",
    "        acc = (torch.sum(self.outputs == self.labels).item() / (self.shape[0]*self.shape[1]*self.shape[2]*self.shape[3]))\n",
    "        acc_mIou = 0.\n",
    "        acc_miou_p = 0.\n",
    "        acc_miou_n = 0.\n",
    "\n",
    "        for i in np.unique(self.labels.detach().numpy()):\n",
    "            for j in range(self.shape[0]):\n",
    "                acc_mIou += ((torch.sum((self.outputs[j, 0, :, :] == self.labels[j, 0, :, :]) & (self.labels[j, 0, :, :] ==i)).item() + 1) / (1 + torch.sum(self.outputs[j, 0, :, :] == i) + torch.sum(self.labels[j, 0, :, :] == i) - torch.sum((self.outputs[j, 0, :, :] == self.labels[j, 0, :, :]) & (self.labels[j, 0, :, :] == i))).item())\n",
    "                acc_miou_n += ((torch.sum((self.outputs[j, 0, :, :] == self.labels[j, 0, :, :]) & (self.labels[j, 0, :, :] ==0)).item() + 1) / (1 + torch.sum(self.outputs[j, 0, :, :] == 0) + torch.sum(self.labels[j, 0, :, :] == 0) - torch.sum((self.outputs[j, 0, :, :] == self.labels[j, 0, :, :]) & (self.labels[j, 0, :, :] == 0))).item())\n",
    "                acc_miou_p += ((torch.sum((self.outputs[j, 0, :, :] == self.labels[j, 0, :, :]) & (self.labels[j, 0, :, :] ==1)).item() + 1) / (1 + torch.sum(self.outputs[j, 0, :, :] == 1) + torch.sum(self.labels[j, 0, :, :] == 1) - torch.sum((self.outputs[j, 0, :, :] == self.labels[j, 0, :, :]) & (self.labels[j, 0, :, :] == 1))).item())\n",
    "        acc_mIou /= (np.unique(self.labels.detach().numpy()).shape[0] * self.shape[0])\n",
    "        acc_miou_p  /= (np.unique(self.labels.detach().numpy()).shape[0] * self.shape[0])\n",
    "        acc_miou_n  /= (np.unique(self.labels.detach().numpy()).shape[0] * self.shape[0])\n",
    "        return acc, acc_mIou, acc_miou_p, acc_miou_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model_train():\n",
    "    def __init__(self, model, dataloader, evaluator, optimizer, num_epoch, state, device):\n",
    "        self.model = model \n",
    "        self.dataloader = dataloader\n",
    "        self.evaluator = evaluator\n",
    "        self.optimizer = optimizer\n",
    "        self.num_epoch = num_epoch\n",
    "        self.state = state\n",
    "        self.device = device\n",
    "        self.running_loss = 0.\n",
    "        self.running_acc = 0.\n",
    "        self.running_acc_mIou = 0.\n",
    "        self.running_acc_miou_p = 0.\n",
    "        self.running_acc_miou_n = 0.\n",
    "        self.best_acc = 0.\n",
    "        self.acc_history_s = []\n",
    "        self.acc_history = []\n",
    "        self.acc_mIou_history_s = []\n",
    "        self.acc_mIou_history = []\n",
    "        \n",
    "    def train(self):\n",
    "        save_num = 1\n",
    "        for epoch in range(num_epoch):\n",
    "            for state in self.state:\n",
    "                self.running_loss = 0.\n",
    "                self.running_acc = 0.\n",
    "                self.running_acc_mIou = 0.\n",
    "                self.running_acc_miou_p = 0.\n",
    "                self.running_acc_miou_n = 0.\n",
    "                if state == \"train\":\n",
    "                    self.model.train()\n",
    "                else:\n",
    "                    self.model.eval()\n",
    "                for inputs, labels in self.dataloader[state]:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    with torch.autograd.set_grad_enabled(state==\"train\"):\n",
    "                        outputs = self.model(inputs)\n",
    "                        loss = self.evaluator(outputs, labels).loss_fn()\n",
    "                        acc, acc_mIou, acc_miou_p, acc_miou_n = self.evaluator(outputs, labels).acc_fn()\n",
    "                    if state == \"train\":\n",
    "                        self.optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        self.optimizer.step()\n",
    "                    self.running_loss += loss.item() * inputs.size(0)\n",
    "                    self.running_acc += acc * inputs.size(0)\n",
    "                    self.running_acc_mIou += acc_mIou * inputs.size(0)\n",
    "                    self.running_acc_miou_p += acc_miou_p * inputs.size(0)\n",
    "                    self.running_acc_miou_n += acc_miou_n * inputs.size(0)\n",
    "                    self.acc_history_s.append(self.running_acc)\n",
    "                    self.acc_mIou_history_s.append(self.running_acc_mIou)\n",
    "                epoch_loss = self.running_loss / len(self.dataloader[state].dataset)\n",
    "                epoch_acc = self.running_acc / len(self.dataloader[state].dataset)\n",
    "                epoch_acc_mIou = self.running_acc_mIou / len(self.dataloader[state].dataset)\n",
    "                epoch_acc_miou_p = self.running_acc_miou_p / len(self.dataloader[state].dataset)\n",
    "                epoch_acc_miou_n = self.running_acc_miou_n / len(self.dataloader[state].dataset) \n",
    "                print(\"Epoch {}/{} __ Phase {} loss: {:.4f}, acc: {:.4f}, acc_mIou: {:.4f}, acc_miou_p: {:.4f}, acc_miou_n: {:.4f}\". format(epoch+1, num_epoch, state, epoch_loss, epoch_acc, epoch_acc_mIou, epoch_acc_miou_p, epoch_acc_miou_n))\n",
    "                \n",
    "                if state == \"eval\":\n",
    "                    print(\"{}\".format(\"_\"*45))\n",
    "                    self.acc_history.append(epoch_acc)\n",
    "                    self.acc_mIou_history.append(epoch_acc_mIou)\n",
    "                    if epoch_acc_miou_p > self.best_acc:\n",
    "                        self.best_acc = epoch_acc_miou_p\n",
    "                        best_model_wts = copy.deepcopy(self.model.state_dict())\n",
    "                    save_num += 1\n",
    "        self.model.load_state_dict(best_model_wts)\n",
    "        return self.model, (self.acc_history, self.acc_mIou_history, self.acc_history_s, self.acc_mIou_history_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"C:\\Users\\风\\Desktop\\表面缺陷检测\\BSData-main\\BSData-main\" # 文件位置\n",
    "state = [\"train\", \"eval\"]\n",
    "input_size = (256, 512) # 用于训练的文件大小\n",
    "batch_size = 2 \n",
    "shuffle = True\n",
    "num_workers = 0\n",
    "pin_memory = True\n",
    "drop_last = True\n",
    "\n",
    "lr = 1e-3\n",
    "beta1 = 0.9\n",
    "beta2 = 0.999\n",
    "epsilon = 1e-8\n",
    "weight_decay = 0.\n",
    "amsgrad = False\n",
    "num_epoch = 50 # epoch数\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.ToTensor()\n",
    "])\n",
    "\n",
    "image_datasets = dataset_defectDetection(path, transform=transform)\n",
    "torch.manual_seed(7)\n",
    "image_datasets_split = random_split(image_datasets, [len(image_datasets)//5, len(image_datasets)-len(image_datasets)//5])\n",
    "\n",
    "loader = {\n",
    "    \"train\": DataLoader(image_datasets_split[1], batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=pin_memory, drop_last=drop_last),\n",
    "    \"eval\": DataLoader(image_datasets_split[0], batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, pin_memory=pin_memory, drop_last=drop_last), \n",
    "}\n",
    "\n",
    "model = SegNet(input_size, device).to(device)\n",
    "optimizer = torch.optim.Adam(filter(lambda param: param.requires_grad, model.parameters()), lr=lr, betas=[beta1, beta2], eps=epsilon, weight_decay=weight_decay, amsgrad=amsgrad)\n",
    "model = model_train(model, loader, evaluator, optimizer, num_epoch, state, device)\n",
    "model, Acc = model.train()\n",
    "\n",
    "plt.title(\"Validation Accuracy vs Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1, len(Acc[0])+1), Acc[0])\n",
    "plt.plot(range(1, len(Acc[1])+1), Acc[1])\n",
    "plt.ylim((0, 1))\n",
    "plt.xticks(np.arange(1, len(Acc[0])+1, 5))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
